{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff3f0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution status: Initating program\n",
      "Execution status: all libraries imported\n",
      "Execution status: transformations\n",
      "Execution status: defining training and evaluation\n",
      "Execution status: Dataset paths and labels loaded\n",
      "Execution status: Device set to cuda\n",
      "Execution status: Passed all prechecks, starting implementation\n",
      "\t step 1: Model initialized\n",
      "\t step 2: Optimizer initialized\n",
      "\t step 3: Dataset initialized\n",
      "\t step 4: Data loader initiated\n",
      "\t step 5: Initializing training loop\n",
      "\t\tEpoch 1/5: \n",
      "\t\t\tInitiating: Training Cycle\n",
      "\t\t\tInitiating: Evaluating Cycle\n",
      "\t\t\t\tAccuracy: 0.1429, \n",
      "\t\t\t\tDice Score: 0.4367\n",
      "Model saved to saved_models/multitask_model.pth\n",
      "\t\tEpoch 2/5: \n",
      "\t\t\tInitiating: Training Cycle\n",
      "\t\t\tInitiating: Evaluating Cycle\n",
      "\t\t\t\tAccuracy: 0.1429, \n",
      "\t\t\t\tDice Score: 0.4237\n",
      "\t\t\tNo improvement for 1 epoch(s).\n",
      "\t\tEpoch 3/5: \n",
      "\t\t\tInitiating: Training Cycle\n",
      "\t\t\tInitiating: Evaluating Cycle\n",
      "\t\t\t\tAccuracy: 0.2857, \n",
      "\t\t\t\tDice Score: 0.4323\n",
      "Model saved to saved_models/multitask_model.pth\n",
      "\t\tEpoch 4/5: \n",
      "\t\t\tInitiating: Training Cycle\n",
      "\t\t\tInitiating: Evaluating Cycle\n",
      "\t\t\t\tAccuracy: 0.2143, \n",
      "\t\t\t\tDice Score: 0.4348\n",
      "\t\t\tNo improvement for 1 epoch(s).\n",
      "\t\tEpoch 5/5: \n",
      "\t\t\tInitiating: Training Cycle\n",
      "\t\t\tInitiating: Evaluating Cycle\n",
      "\t\t\t\tAccuracy: 0.3571, \n",
      "\t\t\t\tDice Score: 0.4269\n",
      "Model saved to saved_models/multitask_model.pth\n",
      "Execution status: saving model\n",
      "Model saved to saved_models/multitask_model.pth\n",
      "Execution status: Program completed successfully\n"
     ]
    }
   ],
   "source": [
    "#############################################################################################################################################\n",
    "#Chapter 1: presetups\n",
    "#############################################################################################################################################\n",
    "\n",
    "# section: importing libraries\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "print(\"Execution status: Initating program\")\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "print(\"Execution status: all libraries imported\")\n",
    "\n",
    "\n",
    "# section: seeding for reproducablity\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed()\n",
    "\n",
    "\n",
    "#############################################################################################################################################\n",
    "#Chapter 2: defintions\n",
    "#############################################################################################################################################\n",
    "\n",
    "# section: saving visualization function\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def save_visualization(image_tensor, pred_mask, true_mask, epoch, index):\n",
    "    image = image_tensor.cpu().permute(1, 2, 0).numpy()\n",
    "    pred = torch.sigmoid(pred_mask).cpu().numpy()\n",
    "    true = true_mask.cpu().numpy()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    image = np.clip(image, 0, 1)\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "    axs[1].imshow(pred[0], cmap='Reds')\n",
    "    axs[1].set_title(\"Predicted Mask\")\n",
    "    axs[2].imshow(true[0], cmap='Greens')\n",
    "    axs[2].set_title(\"Ground Truth Mask\")\n",
    "    for ax in axs: ax.axis('off')\n",
    "\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    plt.savefig(f\"results/epoch_{epoch}_sample_{index}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# section: Router\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "class Router(nn.Module):\n",
    "    def __init__(self, in_channels, num_experts=2):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, num_experts),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)  # Returns weights for each expert\n",
    "\n",
    "\n",
    "# section: Dataset loader\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "class IDRiDDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, mask_dirs, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.mask_dirs = mask_dirs\n",
    "        self.mask_suffixes = ['_MA', '_HE', '_EX', '_SE', '_OD']\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        base_name = os.path.splitext(os.path.basename(self.image_paths[idx]))[0]\n",
    "\n",
    "        masks = []\n",
    "        for mask_dir, suffix in zip(self.mask_dirs, self.mask_suffixes):\n",
    "            mask_path = os.path.join(mask_dir, base_name + suffix + \".tif\")\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "            masks.append(np.array(mask))\n",
    "        mask_stack = np.stack(masks, axis=0)  # Shape: (5, H, W)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=np.array(image), mask=mask_stack.transpose(1, 2, 0))\n",
    "            image = augmented['image']\n",
    "            mask_stack = augmented['mask'].permute(2, 0, 1)  # Back to (5, H, W)\n",
    "        return image, torch.tensor(label, dtype=torch.long), mask_stack.float()\n",
    "print(\"Execution status: transformations\")\n",
    "\n",
    "\n",
    "\n",
    "# section: data augumentation\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=15, p=0.3),\n",
    "    A.Affine(translate_percent={\"x\": 0.05, \"y\": 0.05},scale=(0.95, 1.05),rotate=(-15, 15),p=0.3),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "# section: Architecture definition - shared backbone\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "class SharedBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # Remove avgpool and fc\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)  # Output shape: [B, 512, H/32, W/32]\n",
    "\n",
    "\n",
    "\n",
    "# section: Architecture definition - classification\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "class ClassificationExpert(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# section: Architecture definition - segmentation expert\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "class SegmentationExpert(nn.Module):\n",
    "    def __init__(self, in_channels=512, out_channels=5):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, 256, kernel_size=4, stride=2, padding=1),  # 8 → 16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),          # 16 → 32\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),           # 32 → 64\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),            # 64 → 128\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, out_channels, kernel_size=4, stride=2, padding=1),  # 128 → 256\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "# section: Multi task model definition\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.shared = SharedBackbone()\n",
    "        self.router = Router(in_channels=512, num_experts=2)\n",
    "        self.classifier = ClassificationExpert(512, num_classes)\n",
    "        self.segmenter = SegmentationExpert()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.shared(x)  # Shared feature extraction\n",
    "        routing_weights = self.router(features)  # Shape: [B, 2]\n",
    "        class_out = self.classifier(features)  # Shape: [B, num_classes]\n",
    "        seg_out = self.segmenter(features)     # Shape: [B, 5, H, W]\n",
    "        class_gate = routing_weights[:, 0].unsqueeze(1)  # Shape: [B, 1]\n",
    "        seg_gate = routing_weights[:, 1].unsqueeze(1).unsqueeze(2).unsqueeze(3)  # Shape: [B, 1, 1, 1]\n",
    "        gated_class_out = class_gate * class_out\n",
    "        gated_seg_out = seg_gate * seg_out\n",
    "        return gated_class_out, gated_seg_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# section: Loss function\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def multitask_loss(class_pred, class_target, seg_pred, seg_target, alpha=0.5):\n",
    "    classification_loss = nn.CrossEntropyLoss()(class_pred, class_target)\n",
    "    segmentation_loss = nn.BCEWithLogitsLoss()(seg_pred, seg_target)\n",
    "    return alpha * classification_loss + (1 - alpha) * segmentation_loss\n",
    "\n",
    "print(\"Execution status: defining training and evaluation\")\n",
    "\n",
    "\n",
    "# section: traning\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def train(model, dataloader, optimizer,  epoch, device):\n",
    "    model.train()\n",
    "    with open(\"training_log.csv\", \"a\") as f:\n",
    "        if epoch == 0:  # Assuming epoch starts from 0\n",
    "            f.write(\"epoch,batch,loss\\n\")\n",
    "    for batch_idx, (images, labels, masks) in enumerate(dataloader):\n",
    "        images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        class_out, seg_out = model(images)\n",
    "        loss = multitask_loss(class_out, labels, seg_out, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with open(\"training_log.csv\", \"a\") as f:\n",
    "            f.write(f\"{epoch},{batch_idx},{loss.item():.4f}\\n\")\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch * len(dataloader) + batch_idx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# section: Evaluvation\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def evaluate(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    dice_scores = [[] for _ in range(5)]  # For each lesion type\n",
    "    class_correct = [0] * 5\n",
    "    class_total = [0] * 5\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels, masks) in enumerate(dataloader):\n",
    "            images, labels, masks = images.to(device), labels.to(device), masks.to(device)\n",
    "            class_out, seg_out = model(images)\n",
    "            # Classification accuracy per class\n",
    "            preds = torch.argmax(class_out, dim=1)\n",
    "            for i in range(len(labels)):\n",
    "                class_total[labels[i].item()] += 1\n",
    "                if preds[i].item() == labels[i].item():\n",
    "                    class_correct[labels[i].item()] += 1\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            # Dice score per lesion\n",
    "            seg_out = torch.sigmoid(seg_out)\n",
    "            for i in range(5):  # 5 lesion types\n",
    "                intersection = (seg_out[:, i] * masks[:, i]).sum(dim=(1, 2))\n",
    "                union = seg_out[:, i].sum(dim=(1, 2)) + masks[:, i].sum(dim=(1, 2))\n",
    "                dice = (2. * intersection) / (union + 1e-8)\n",
    "                dice_scores[i].extend(dice.cpu().numpy())\n",
    "            # Save visualizations for first batch\n",
    "            if batch_idx == 0:\n",
    "                for i in range(min(2, images.size(0))):\n",
    "                    save_visualization(images[i], seg_out[i], masks[i], epoch, i)\n",
    "                \n",
    "                writer.add_images('Images/original', images[:2], epoch)\n",
    "                for i in range(5):\n",
    "                    writer.add_images(f'Masks/predicted_type_{i}', seg_out[:2, i:i+1], epoch)\n",
    "                    writer.add_images(f'Masks/ground_truth_type_{i}', masks[:2, i:i+1], epoch)\n",
    "    accuracy = total_correct / total_samples\n",
    "    avg_dice = [sum(scores) / len(scores) for scores in dice_scores]\n",
    "    class_acc = [correct / total if total > 0 else 0.0 for correct, total in zip(class_correct, class_total)]\n",
    "    with open(\"task_metrics_log.csv\", \"a\") as f:\n",
    "        f.write(f\"Epoch {epoch}, Overall Accuracy: {accuracy:.4f}, \" +\n",
    "                \", \".join([f\"Class{i}_Acc: {acc:.4f}\" for i, acc in enumerate(class_acc)]) + \", \" +\n",
    "                \", \".join([f\"Lesion{i}_Dice: {dice:.4f}\" for i, dice in enumerate(avg_dice)]) + \"\\n\")\n",
    "    writer.add_scalar('Accuracy/Overall', accuracy, epoch)\n",
    "    writer.add_scalar('Dice/Overall', sum(avg_dice) / len(avg_dice), epoch)\n",
    "    return accuracy, sum(avg_dice) / len(avg_dice)\n",
    "\n",
    "\n",
    "\n",
    "# section: Save model\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "def save_model(model, path=\"saved_models/multitask_model.pth\"):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"\\t\\t\\t\\tModel saved to {path}\")\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################################################################\n",
    "#Chapter 3 Implementation\n",
    "#############################################################################################################################################\n",
    "\n",
    "# section: setting path of dataset and loading data\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "image_dir = r\"D:\\Project_Space\\5.retina\\retina_data\\B. Disease Grading\\1. Original Images\\a. Training Set\"\n",
    "label_csv = r\"D:\\Project_Space\\5.retina\\retina_data\\B. Disease Grading\\2. Groundtruths\\a. IDRiD_Disease Grading_Training Labels.csv\"\n",
    "mask_dirs = [\n",
    "    r\"D:\\Project_Space\\5.retina\\retina_data\\A. Segmentation\\2. All Segmentation Groundtruths\\a. Training Set\\1. Microaneurysms\",\n",
    "    r\"D:\\Project_Space\\5.retina\\retina_data\\A. Segmentation\\2. All Segmentation Groundtruths\\a. Training Set\\2. Haemorrhages\",\n",
    "    r\"D:\\Project_Space\\5.retina\\retina_data\\A. Segmentation\\2. All Segmentation Groundtruths\\a. Training Set\\3. Hard Exudates\",\n",
    "    r\"D:\\Project_Space\\5.retina\\retina_data\\A. Segmentation\\2. All Segmentation Groundtruths\\a. Training Set\\4. Soft Exudates\",\n",
    "    r\"D:\\Project_Space\\5.retina\\retina_data\\A. Segmentation\\2. All Segmentation Groundtruths\\a. Training Set\\5. Optic Disc\"\n",
    "]\n",
    "image_paths = sorted(glob.glob(image_dir + r\"\\*.jpg\"))\n",
    "label_df = pd.read_csv(label_csv)\n",
    "filename_to_label = dict(zip(label_df['Image name'], label_df['Retinopathy grade']))\n",
    "labels = [filename_to_label[os.path.splitext(os.path.basename(p))[0]] for p in image_paths]\n",
    "print(\"Execution status: Dataset paths and labels loaded\")\n",
    "\n",
    "val_image_dir = r\"D:\\Project_Space\\5.retina\\retina_data\\B. Disease Grading\\1. Original Images\\b. Testing Set\"\n",
    "val_label_csv = r\"D:\\Project_Space\\5.retina\\retina_data\\B. Disease Grading\\2. Groundtruths\\b. IDRiD_Disease Grading_Testing Labels.csv\"\n",
    "val_mask_dirs = [\n",
    "    r\"D:\\\\Project_Space\\\\5.retina\\\\retina_data\\\\A. Segmentation\\\\2. All Segmentation Groundtruths\\\\b. Testing Set\\\\1. Microaneurysms\",\n",
    "    r\"D:\\\\Project_Space\\\\5.retina\\\\retina_data\\\\A. Segmentation\\\\2. All Segmentation Groundtruths\\\\b. Testing Set\\\\2. Haemorrhages\",\n",
    "    r\"D:\\\\Project_Space\\\\5.retina\\\\retina_data\\\\A. Segmentation\\\\2. All Segmentation Groundtruths\\\\b. Testing Set\\\\3. Hard Exudates\",\n",
    "    r\"D:\\\\Project_Space\\\\5.retina\\\\retina_data\\\\A. Segmentation\\\\2. All Segmentation Groundtruths\\\\b. Testing Set\\\\4. Soft Exudates\",\n",
    "    r\"D:\\\\Project_Space\\\\5.retina\\\\retina_data\\\\A. Segmentation\\\\2. All Segmentation Groundtruths\\\\b. Testing Set\\\\5. Optic Disc\"\n",
    "]\n",
    "val_image_paths = sorted(glob.glob(val_image_dir + r\"\\\\*.jpg\"))\n",
    "val_label_df = pd.read_csv(val_label_csv)\n",
    "val_filename_to_label = dict(zip(val_label_df['Image name'], val_label_df['Retinopathy grade']))\n",
    "val_labels = [val_filename_to_label[os.path.splitext(os.path.basename(p))[0]] for p in val_image_paths]\n",
    "\n",
    "\n",
    "# section: Choosing GPU\n",
    "#--------------------------------------------------------------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Execution status: Device set to\", device)\n",
    "\n",
    "\n",
    "# section: implementation\n",
    "#---------------------------------------------------------------------------------a-----------------------------------\n",
    "print(\"Execution status: Passed all prechecks, starting implementation\")\n",
    "model = MultiTaskModel(num_classes=5).to(device)\n",
    "dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "writer = SummaryWriter(log_dir=\"runs/multitask_experiment\")\n",
    "writer.add_graph(model, dummy_input)\n",
    "print(\"\\t step 1: Model initialized\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "print(\"\\t step 2: Optimizer initialized\")\n",
    "dataset = IDRiDDataset(image_paths, labels, mask_dirs, transform=transform)\n",
    "val_dataset = IDRiDDataset(val_image_paths, val_labels, val_mask_dirs, transform=transform)\n",
    "print(\"\\t step 3: Dataset initialized\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "print(\"\\t step 4: Data loader initiated\")\n",
    "num_epochs =5\n",
    "print(\"\\t step 5: Initializing training loop\")\n",
    "writer = SummaryWriter(log_dir=\"runs/multitask_training\")\n",
    "best_score = None\n",
    "patience = 3\n",
    "no_improve_count = 0\n",
    "monitor_metric = 'accuracy'\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\t\\tEpoch {epoch+1}/{num_epochs}: \\n\\t\\t\\tInitiating: Training Cycle\")\n",
    "    train(model, dataloader, optimizer, epoch, device)\n",
    "    print(f\"\\t\\t\\tInitiating: Evaluating Cycle\")\n",
    "    acc, dice = evaluate(model, val_dataloader, device, epoch)\n",
    "    print(f\"\\t\\t\\t\\tAccuracy: {acc:.4f}, \\n\\t\\t\\t\\tDice Score: {dice:.4f}\")\n",
    "    current_score = acc if monitor_metric == 'accuracy' else dice\n",
    "    if best_score is None or current_score > best_score:\n",
    "        best_score = current_score\n",
    "        no_improve_count = 0\n",
    "        save_model(model)\n",
    "    else:\n",
    "        no_improve_count += 1\n",
    "        print(f\"\\t\\t\\tNo improvement for {no_improve_count} epoch(s).\")\n",
    "    if no_improve_count >= patience:\n",
    "        print(f\"\\t\\tEarly stopping triggered at epoch {epoch+1}.\")\n",
    "        break\n",
    "print(\"Execution status: saving model\")\n",
    "save_model(model)\n",
    "writer.close()\n",
    "print(\"Execution status: Program completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
